import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextRequest, NextResponse } from "next/server";
import knowledgeBase from "@/src/entities/chatbot/model/knowledge-base.json";

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY || "");

const MODELS = ["gemini-2.5-flash", "gemini-2.5-flash-lite"];

const OFF_TOPIC_KEYWORDS = [
  "ë‚ ì”¨",
  "ì£¼ì‹",
  "ì½”ì¸",
  "ë¡œë˜",
  "ìš´ì„¸",
  "ìŒì‹",
  "ë§›ì§‘",
  "ë‰´ìŠ¤",
  "ì •ì¹˜",
  "ì—°ì˜ˆ",
  "ê²Œì„ì¶”ì²œ",
  "ì˜¤ëŠ˜ ë­í•´",
  "ì‹¬ì‹¬í•´",
  "ë¹„ì™€",
];

function isOffTopic(message: string): boolean {
  const cleanMessage = message.replace(/\s+/g, "").toLowerCase();
  return OFF_TOPIC_KEYWORDS.some((keyword) => cleanMessage.includes(keyword));
}

function formatKnowledgeBase(): string {
  let formatted = `ì£¼ì œ: ${knowledgeBase.topic}\n`;
  formatted += `ì„¤ëª…: ${knowledgeBase.description}\n\n`;
  formatted += "=== ì œê³µëœ ì •ë³´ ===\n\n";

  knowledgeBase.data.forEach((item, index) => {
    formatted += `${index + 1}. ${item.category}\n`;
    formatted += `${item.content}\n\n`;
  });

  return formatted;
}

function createSystemPrompt(): string {
  const knowledgeContent = formatKnowledgeBase();

  return `ë‹¹ì‹ ì€ ì œê³µëœ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ ë‹µë³€í•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

${knowledgeContent}

[ë‹µë³€ ê·œì¹™]
1. ìœ„ ì •ë³´ì™€ ì§ì ‘ ê´€ë ¨ëœ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤.
2. ê´€ë ¨ì„±ì´ ìˆë‹¤ë©´ ì¼ë°˜ì ì¸ ì§€ì‹ì„ ë³´ì¡°ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì„ ë¬¼ì–´ë³´ë©´ "ì£„ì†¡í•˜ì§€ë§Œ, ì œê³µëœ ì •ë³´ì—ì„œëŠ” í•´ë‹¹ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”."ë¼ê³  ì•ˆë‚´í•©ë‹ˆë‹¤.
4. ì™„ì „íˆ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” "ì£„ì†¡í•˜ì§€ë§Œ, ì €ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ì— ê´€í•œ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."ë¼ê³  ì‘ë‹µí•©ë‹ˆë‹¤.
5. ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.
6. ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.`;
}
export async function POST(request: NextRequest) {
  try {
    const { message } = await request.json();
    if (!message)
      return NextResponse.json({ error: "ë©”ì‹œì§€ ëˆ„ë½" }, { status: 400 });

    if (isOffTopic(message)) {
      return NextResponse.json({
        response:
          "ì£„ì†¡í•˜ì§€ë§Œ, ì €ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ì™€ ê°œë°œ ì—­ëŸ‰ì— ê´€í•œ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  í”„ë¡œì íŠ¸ë‚˜ ê¸°ìˆ  ìŠ¤íƒì— ëŒ€í•´ ë¬¼ì–´ë´ ì£¼ì„¸ìš”! ğŸ˜Š",
        success: true,
        usedModel: "static-filter",
      });
    }

    const systemInstruction = createSystemPrompt();

    for (const modelName of MODELS) {
      try {
        const model = genAI.getGenerativeModel({
          model: modelName,
          systemInstruction: systemInstruction,
        });
        const result = await model.generateContent(message);
        const text = result.response.text();

        return NextResponse.json({
          response: text,
          success: true,
          usedModel: modelName,
        });
      } catch (error: any) {
        if (error.status === 429) {
          console.warn(`${modelName} í•œë„ ì´ˆê³¼, ë‹¤ìŒ ëª¨ë¸ë¡œ ì‹œë„í•©ë‹ˆë‹¤.`);
          continue;
        }
        console.error(`Error with ${modelName}:`, error);
        throw error;
      }
    }

    return NextResponse.json(
      { error: "ëª¨ë“  AI ëª¨ë¸ì˜ ì¼ì¼ í•œë„ê°€ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤." },
      { status: 429 }
    );
  } catch (error) {
    console.error("Chat Error:", error);
    return NextResponse.json({ error: "ì‘ë‹µ ìƒì„± ì‹¤íŒ¨" }, { status: 500 });
  }
}
