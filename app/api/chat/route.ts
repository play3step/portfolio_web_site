import { GoogleGenerativeAI } from "@google/generative-ai";
import { NextRequest, NextResponse } from "next/server";
import knowledgeBase from "@/src/entities/chatbot/model/knowledge-base.json";
import { Redis } from "@upstash/redis";
import { Ratelimit } from "@upstash/ratelimit";

const redis = new Redis({
  url: process.env.KV_REST_API_URL,
  token: process.env.KV_REST_API_TOKEN,
});

const ratelimit = new Ratelimit({
  redis: redis,
  limiter: Ratelimit.slidingWindow(4, "1 m"),
  analytics: true,
});

const genAI = new GoogleGenerativeAI(process.env.GOOGLE_GEMINI_API_KEY || "");
const MODELS = ["gemini-2.5-flash", "gemini-2.5-flash-lite"];

const OFF_TOPIC_KEYWORDS = [
  "ë‚ ì”¨",
  "ì£¼ì‹",
  "ì½”ì¸",
  "ë¡œë˜",
  "ìš´ì„¸",
  "ìŒì‹",
  "ë§›ì§‘",
  "ë‰´ìŠ¤",
  "ì •ì¹˜",
  "ì—°ì˜ˆ",
  "ê²Œì„ì¶”ì²œ",
  "ì˜¤ëŠ˜ ë­í•´",
  "ì‹¬ì‹¬í•´",
  "ë¹„ì™€",
];

function isOffTopic(message: string): boolean {
  const cleanMessage = message.replace(/\s+/g, "").toLowerCase();
  return OFF_TOPIC_KEYWORDS.some((keyword) => cleanMessage.includes(keyword));
}

// function formatKnowledgeBase(): string {
//   let formatted = `ì£¼ì œ: ${knowledgeBase.topic}\n`;
//   formatted += `ì„¤ëª…: ${knowledgeBase.description}\n\n`;
//   formatted += "=== ì œê³µëœ ì •ë³´ ===\n\n";

//   knowledgeBase.data.forEach((item, index) => {
//     formatted += `${index + 1}. ${item.category}\n`;
//     formatted += `${item.content}\n\n`;
//   });

//   return formatted;
// }

function createSystemPrompt(): string {
  return `
    ë‹¹ì‹ ì€ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œìì˜ í¬íŠ¸í´ë¦¬ì˜¤ ì±—ë´‡ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ì¡´ì¬ ëª©ì ì€ ì˜¤ì§ **[ì§€ì‹ ë² ì´ìŠ¤]ì— ìˆëŠ” ì‘ì„±ìì˜ ì—­ëŸ‰ê³¼ ê²½í—˜ì„ ì–´í•„í•˜ëŠ” ê²ƒ**ì…ë‹ˆë‹¤.
    
    === [ì§€ì‹ ë² ì´ìŠ¤] ===
    ${JSON.stringify(knowledgeBase, null, 2)}
    =====================

    [ë‹µë³€ ì›ì¹™]
    1. **Strict Anchoring (í¬íŠ¸í´ë¦¬ì˜¤ ì¤‘ì‹¬ì£¼ì˜):** - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì¼ë°˜ì ì¸ ì§€ì‹(ì˜ˆ: "Next.jsê°€ ë­ì•¼?", "SSRì´ ë­ì•¼?")ì„ ë¬»ë”ë¼ë„, ì‚¬ì „ì ì¸ ì •ì˜ë§Œ ë‚˜ì—´í•˜ì§€ ë§ˆì„¸ìš”.
       - ë°˜ë“œì‹œ **"ì‘ì„±ìê°€ ì´ ê¸°ìˆ ì„ ì–´ë–¤ í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–»ê²Œ í™œìš©í–ˆëŠ”ì§€"**ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
       - ì‘ì„±ìì˜ ê²½í—˜ê³¼ ì—°ê²°ë˜ì§€ ì•ŠëŠ” ì¼ë°˜ ìƒì‹ ì§ˆë¬¸ì€ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.

    2. **Context Awareness (ë§¥ë½ ì¶”ë¡ ):**
       - "ê±°ê¸°ì„œ í˜ë“¤ì—ˆë˜ ì ì€?", "ê·¸ í”„ë¡œì íŠ¸ëŠ”?" ê°™ì€ ëŒ€ëª…ì‚¬ëŠ” ì´ì „ ëŒ€í™” ë‚´ì—­ì„ í†µí•´ ì¶”ë¡ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.

    3. **Smart Refusal (ë˜‘ë˜‘í•œ ê±°ì ˆ):**
       - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ í¬íŠ¸í´ë¦¬ì˜¤ì™€ **ë…¼ë¦¬ì  ì—°ê²°ê³ ë¦¬**ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ ì •ì¤‘íˆ ê±°ì ˆí•˜ì„¸ìš”.
       - ì˜ˆ: "ì‘ì„±ìì˜ ì¶œì‹  í•™êµ ìœ„ì¹˜" (O -> í•™êµ ìƒí™œë¡œ ì—°ê²° ê°€ëŠ¥í•˜ë¯€ë¡œ ë‹µë³€)
       - ì˜ˆ: "ì„œìš¸ ë§›ì§‘ ì¶”ì²œ" (X -> í¬íŠ¸í´ë¦¬ì˜¤ì™€ ë¬´ê´€í•˜ë¯€ë¡œ ê±°ì ˆ)
       - ì˜ˆ: "ë¦¬ì•¡íŠ¸ íŠœí† ë¦¬ì–¼ ì•Œë ¤ì¤˜" (â–³ -> "ì‘ì„±ìëŠ” ë¦¬ì•¡íŠ¸ë¥¼ ì´ë ‡ê²Œ ì¼ìŠµë‹ˆë‹¤"ë¡œ ë°©ì–´, íŠœí† ë¦¬ì–¼ ì‘ì„±ì€ ê±°ì ˆ)

    4. **Tone & Manner:**
       - ë©´ì ‘ê´€ì—ê²Œ ì„¤ëª…í•˜ë“¯ ì‹ ë¢°ê° ìˆëŠ” 'í•´ìš”ì²´'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
       - ë¶ˆí•„ìš”í•œ ë¯¸ì‚¬ì—¬êµ¬ë¥¼ ë¹¼ê³  í•µì‹¬(ì‘ì„±ìì˜ ê¸°ì—¬ë„, ì„±ê³¼) ìœ„ì£¼ë¡œ ë§í•˜ì„¸ìš”.
  `;
}

export async function POST(request: NextRequest) {
  try {
    const ip = request.headers.get("x-forwarded-for") ?? "127.0.0.1";
    const { success } = await ratelimit.limit(ip);

    if (!success) {
      return NextResponse.json(
        {
          response:
            "ë„ˆë¬´ ì§§ì€ ì‹œê°„ì— ë§ì€ ì§ˆë¬¸ì„ í•˜ì…¨ë„¤ìš”! ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ğŸ˜Š",
          success: true,
        },
        { status: 429 }
      );
    }

    const { message } = await request.json();
    if (!message)
      return NextResponse.json({ error: "ë©”ì‹œì§€ ëˆ„ë½" }, { status: 400 });

    if (isOffTopic(message)) {
      return NextResponse.json({
        response:
          "ì£„ì†¡í•˜ì§€ë§Œ, ì €ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ˜Š",
        success: true,
        usedModel: "static-filter",
      });
    }

    const systemInstruction = createSystemPrompt();

    for (const modelName of MODELS) {
      try {
        const model = genAI.getGenerativeModel({
          model: modelName,
          systemInstruction: systemInstruction,
        });
        const result = await model.generateContent(message);
        const text = result.response.text();

        return NextResponse.json({
          response: text,
          success: true,
          usedModel: modelName,
        });
      } catch (error: any) {
        if (error.status === 429) {
          console.warn(`${modelName} í•œë„ ì´ˆê³¼, ë‹¤ìŒ ëª¨ë¸ ì‹œë„...`);
          continue;
        }
        throw error;
      }
    }

    return NextResponse.json(
      { error: "ëª¨ë“  AI ëª¨ë¸ì˜ í•œë„ê°€ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤." },
      { status: 429 }
    );
  } catch (error) {
    console.error("Chat Error:", error);
    return NextResponse.json({ error: "ì‘ë‹µ ìƒì„± ì‹¤íŒ¨" }, { status: 500 });
  }
}
